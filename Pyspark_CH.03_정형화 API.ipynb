{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8422b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:44:06.034559Z",
     "start_time": "2023-04-05T07:44:05.771133Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeb4a695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:25:56.014124Z",
     "start_time": "2023-04-05T00:25:56.000161Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ebf2a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:25:56.029122Z",
     "start_time": "2023-04-05T00:25:56.017136Z"
    }
   },
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd98427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:25:56.044044Z",
     "start_time": "2023-04-05T00:25:56.031078Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install py4j==0.10.9.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c3216c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:25:56.059038Z",
     "start_time": "2023-04-05T00:25:56.045079Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c286bff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:44:31.618477Z",
     "start_time": "2023-04-05T07:44:19.542120Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName('AuthorsAges')\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "797463f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:27.483523Z",
     "start_time": "2023-04-05T00:25:56.060996Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|avg(age)|\n",
      "+------+--------+\n",
      "|Brooke|    22.5|\n",
      "| Denny|    31.0|\n",
      "| Jules|    30.0|\n",
      "|    TD|    35.0|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df = spark.createDataFrame([('Brooke',20), ('Denny',31), ('Jules',30),(\"TD\",35),('Brooke',25)], ['name','age'])\n",
    "\n",
    "avg_df = data_df.groupBy('name').agg(avg('age'))\n",
    "avg_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cee49c",
   "metadata": {},
   "source": [
    "# 스키마 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ab4ff",
   "metadata": {},
   "source": [
    "## 프로그래밍 스타일로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e4847da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:27.498481Z",
     "start_time": "2023-04-05T00:26:27.485515Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([StructField(\"author\", StringType(), False),\n",
    "                    StructField(\"title\", StringType(), False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e72da88d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:27.513441Z",
     "start_time": "2023-04-05T00:26:27.502470Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('author', StringType(), False), StructField('title', StringType(), False)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9065317b",
   "metadata": {},
   "source": [
    "## DDL 사용하여 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5a4a32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:27.528401Z",
     "start_time": "2023-04-05T00:26:27.515438Z"
    }
   },
   "outputs": [],
   "source": [
    "schema = \"author STRING, title STRING, pages INT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67150874",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T08:21:48.572821Z",
     "start_time": "2023-03-31T08:21:36.515403Z"
    }
   },
   "source": [
    "# p.52 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c486bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:41.517382Z",
     "start_time": "2023-04-05T00:26:27.530394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# DDL 사용하여 스키마 정의\n",
    "#schema = \"'ID' INT, 'First' STRING, 'Last' STRING, 'Url' STRING, 'Published' STRING, 'HITS' INT, 'Campaigns' ARRAY<STRING>\"\n",
    "\n",
    "schema = StructType([\n",
    "   StructField(\"Id\", IntegerType(), False),\n",
    "   StructField(\"First\", StringType(), False),\n",
    "   StructField(\"Last\", StringType(), False),\n",
    "   StructField(\"Url\", StringType(), False),\n",
    "   StructField(\"Published\", StringType(), False),\n",
    "   StructField(\"Hits\", IntegerType(), False),\n",
    "   StructField(\"Campaigns\", ArrayType(StringType()), False)])\n",
    "\n",
    "data = [[1, \"Jules\", \"Damji\", \"https://tinyurl.1\", \"1/4/2016\", 4535, [\"twitter\", \"LinkedIn\"]],\n",
    "       [2, \"Brooke\",\"Wenig\",\"https://tinyurl.2\", \"5/5/2018\", 8908, [\"twitter\", \"LinkedIn\"]],\n",
    "       [3, \"Denny\", \"Lee\", \"https://tinyurl.3\",\"6/7/2019\",7659, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "       [4, \"Tathagata\", \"Das\",\"https://tinyurl.4\", \"5/12/2018\", 10568, [\"twitter\", \"FB\"]],\n",
    "       [5, \"Matei\",\"Zaharia\", \"https://tinyurl.5\", \"5/14/2014\", 40578, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "       [6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", \"3/2/2015\", 25568, [\"twitter\", \"LinkedIn\"]]\n",
    "      ]\n",
    "\n",
    "# 메인 프로그램\n",
    "\n",
    "#스파크세션 생성\n",
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"Example-3_6\")\n",
    "        .getOrCreate())\n",
    "\n",
    "blogs_df = spark.createDataFrame(data, schema)\n",
    "blogs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa1090c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:41.532347Z",
     "start_time": "2023-04-05T00:26:41.518379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = false)\n",
      " |-- First: string (nullable = false)\n",
      " |-- Last: string (nullable = false)\n",
      " |-- Url: string (nullable = false)\n",
      " |-- Published: string (nullable = false)\n",
      " |-- Hits: integer (nullable = false)\n",
      " |-- Campaigns: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogs_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcad0f6a",
   "metadata": {},
   "source": [
    "# 로우 (p.58~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7209f3ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:41.547354Z",
     "start_time": "2023-04-05T00:26:41.533378Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "784c518a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:41.562312Z",
     "start_time": "2023-04-05T00:26:41.549298Z"
    }
   },
   "outputs": [],
   "source": [
    "blog_row = Row(6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", 255568, \"3/2/2015\", [\"twitter\", \"LinkedIn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55fd21a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:41.577275Z",
     "start_time": "2023-04-05T00:26:41.563259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reynold'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ec89060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:55.661987Z",
     "start_time": "2023-04-05T00:26:41.578219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|      Authors|State|\n",
      "+-------------+-----+\n",
      "|Matei Zaharia|   CA|\n",
      "|  Reynold Xin|   CA|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows = [Row(\"Matei Zaharia\", \"CA\"), Row(\"Reynold Xin\", \"CA\")]\n",
    "author_df = spark.createDataFrame(rows, [\"Authors\", \"State\"])\n",
    "author_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e28913",
   "metadata": {},
   "source": [
    "# DataFrameReader/DataFrameWriter 사용하기(p.60~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48cdaee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:44:40.566480Z",
     "start_time": "2023-04-05T07:44:38.112740Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Chapter03\").getOrCreate()\n",
    "\n",
    "# 스키마 정의\n",
    "fire_schema = StructType([StructField('CallNumber', IntegerType(), True),\n",
    "                         StructField('UnitID', StringType(), True),\n",
    "                         StructField('IncidentNumber', IntegerType(), True),\n",
    "                         StructField('CallType', StringType(), True),\n",
    "                         StructField('CallDate', StringType(), True),\n",
    "                         StructField('WatchDate', StringType(), True),\n",
    "                         StructField('CallFinalDisposition', StringType(), True),\n",
    "                         StructField('AvailableDtTm', StringType(), True), \n",
    "                         StructField('Address', StringType(), True),\n",
    "                         StructField('City', StringType(), True), \n",
    "                         StructField('Zipcode', StringType(), True), \n",
    "                         StructField('Battalion', StringType(), True),\n",
    "                         StructField('StationArea', StringType(), True), \n",
    "                         StructField('Box', StringType(), True),\n",
    "                         StructField('OriginalPriority', StringType(), True),\n",
    "                         StructField('Priority', StringType(), True), \n",
    "                         StructField('FinalPriority', IntegerType(), True), \n",
    "                         StructField('ASLUnit', BooleanType(), True), \n",
    "                         StructField('CalltypeGroup', StringType(), True), \n",
    "                         StructField('NumAlarms', IntegerType(), True),\n",
    "                         StructField('UnitType', StringType(), True), \n",
    "                         StructField('UnitSequenceInCallDistrict', IntegerType(), True), \n",
    "                         StructField('FirePreventionDistirct', StringType(), True),\n",
    "                         StructField('SupervisiorDistrict', StringType(), True),\n",
    "                         StructField('Neighborhood', StringType(), True),\n",
    "                         StructField('Location', StringType(), True), \n",
    "                         StructField('RowID', StringType(), True),\n",
    "                         StructField('Delay', FloatType(), True) \n",
    "                         ])\n",
    "\n",
    "sf_fire_file = \"C:/0. Modeling/1. Modeling Code/pyspark_dataset/LearningSparkV2-master/chapter3/data/sf-fire-calls.csv\"\n",
    "fire_df = spark.read.csv(sf_fire_file, header = True, schema = fire_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e7c2b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:44:43.903873Z",
     "start_time": "2023-04-05T07:44:42.147949Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+-------------------+---------------------+-------------------------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|CallType        |CallDate  |WatchDate |CallFinalDisposition|AvailableDtTm         |Address                    |City|Zipcode|Battalion|StationArea|Box |OriginalPriority|Priority|FinalPriority|ASLUnit|CalltypeGroup|NumAlarms|UnitType|UnitSequenceInCallDistrict|FirePreventionDistirct|SupervisiorDistrict|Neighborhood         |Location                             |RowID        |Delay    |\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+-------------------+---------------------+-------------------------------------+-------------+---------+\n",
      "|20110016  |T13   |2003235       |Structure Fire  |01/11/2002|01/10/2002|Other               |01/11/2002 01:51:44 AM|2000 Block of CALIFORNIA ST|SF  |94109  |B04      |38         |3362|3               |3       |3            |false  |null         |1        |TRUCK   |2                         |4                     |5                  |Pacific Heights      |(37.7895840679362, -122.428071912459)|020110016-T13|2.95     |\n",
      "|20110022  |M17   |2003241       |Medical Incident|01/11/2002|01/10/2002|Other               |01/11/2002 03:01:18 AM|0 Block of SILVERVIEW DR   |SF  |94124  |B10      |42         |6495|3               |3       |3            |true   |null         |1        |MEDIC   |1                         |10                    |10                 |Bayview Hunters Point|(37.7337623673897, -122.396113802632)|020110022-M17|4.7      |\n",
      "|20110023  |M41   |2003242       |Medical Incident|01/11/2002|01/10/2002|Other               |01/11/2002 02:39:50 AM|MARKET ST/MCALLISTER ST    |SF  |94102  |B03      |01         |1455|3               |3       |3            |true   |null         |1        |MEDIC   |2                         |3                     |6                  |Tenderloin           |(37.7811772186856, -122.411699931232)|020110023-M41|2.4333334|\n",
      "|20110032  |E11   |2003250       |Vehicle Fire    |01/11/2002|01/10/2002|Other               |01/11/2002 04:16:46 AM|APPLETON AV/MISSION ST     |SF  |94110  |B06      |32         |5626|3               |3       |3            |false  |null         |1        |ENGINE  |1                         |6                     |9                  |Bernal Heights       |(37.7388432849018, -122.423948785199)|020110032-E11|1.5      |\n",
      "|20110043  |B04   |2003259       |Alarms          |01/11/2002|01/10/2002|Other               |01/11/2002 06:01:58 AM|1400 Block of SUTTER ST    |SF  |94109  |B04      |03         |3223|3               |3       |3            |false  |null         |1        |CHIEF   |2                         |4                     |2                  |Western Addition     |(37.7872890372638, -122.424236212664)|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+-------------------+---------------------+-------------------------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4869c6",
   "metadata": {},
   "source": [
    "## 데이터 프레임을 파케이 파일/ SQL 테이블로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24f5b9a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:56.321225Z",
     "start_time": "2023-04-05T00:26:56.307262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67e25683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:56.336184Z",
     "start_time": "2023-04-05T00:26:56.322225Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26e1d615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:44:51.659137Z",
     "start_time": "2023-04-05T07:44:49.473298Z"
    }
   },
   "outputs": [],
   "source": [
    "parquet_path = \"C:/0. Modeling/1. Modeling Code/pyspark_dataset/LearningSparkV2-master/chapter3/data/fire_df.parquet\"\n",
    "fire_df.write.format(\"parquet\").mode('overwrite').save(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5603cf0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:47:55.273446Z",
     "start_time": "2023-04-05T07:47:55.222073Z"
    }
   },
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "\nSyntax error at or near ':'(line 1, pos 1)\n\n== SQL ==\nC:/0. Modeling/1. Modeling Code/pyspark_dataset/LearningSparkV2-master/chapter3/data/few_fire_tbl\n-^^^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b9f1909b2019>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparquet_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/0. Modeling/1. Modeling Code/pyspark_dataset/LearningSparkV2-master/chapter3/data/few_fire_tbl'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfire_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"parquet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'overwrite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveAsTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparquet_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Spark\\spark-3.3.2-bin-hadoop3\\python\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36msaveAsTable\u001b[1;34m(self, name, format, mode, partitionBy, **options)\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveAsTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m     def json(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark-3.3.2-bin-hadoop3\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mParseException\u001b[0m: \nSyntax error at or near ':'(line 1, pos 1)\n\n== SQL ==\nC:/0. Modeling/1. Modeling Code/pyspark_dataset/LearningSparkV2-master/chapter3/data/few_fire_tbl\n-^^^\n"
     ]
    }
   ],
   "source": [
    "parquet_table = 'C:/0. Modeling/1. Modeling Code/pyspark_dataset/LearningSparkV2-master/chapter3/data/few_fire_tbl'\n",
    "fire_df.write.format(\"parquet\").mode('overwrite').saveAsTable(parquet_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c0f66",
   "metadata": {},
   "source": [
    "## 프로젝션과 필터 (p.63~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397db249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:57.071219Z",
     "start_time": "2023-04-05T00:25:55.760Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "few_fire_df = (fire_df\n",
    "              .select(\"IncidentNumber\", \"AvailableDtTm\",\"CallType\")\n",
    "              .where(col(\"CallType\") != \"Medical Incident\"))\n",
    "\n",
    "few_fire_df.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf69bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:57.072216Z",
     "start_time": "2023-04-05T00:25:55.761Z"
    }
   },
   "outputs": [],
   "source": [
    "### 신고로 기록된 Calltype 종류\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "(fire_df\n",
    "    .select(\"CallType\")\n",
    "    .where(col(\"CallType\").isNotNull())\n",
    "    .agg(countDistinct(\"CallType\").alias(\"DistinctCallTypes\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa286437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:57.073214Z",
     "start_time": "2023-04-05T00:25:55.762Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### null이 아닌 신고 타입의 목록\n",
    "\n",
    "(fire_df\n",
    "    .select(\"CallType\")\n",
    "    .where(col(\"CallType\").isNotNull())\n",
    "    .distinct()\n",
    "    .show(10, False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839fedca",
   "metadata": {},
   "source": [
    "## 칼럼 이름 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0bb7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:57.073214Z",
     "start_time": "2023-04-05T00:25:55.763Z"
    }
   },
   "outputs": [],
   "source": [
    "new_fire_df = fire_df.withColumnRenamed(\"Delay\",\"ResponseDelayedinMins\")\n",
    "\n",
    "(new_fire_df\n",
    "    .select(\"ResponseDelayedinMins\")\n",
    "    .where(col(\"ResponseDelayedinMins\")>5)\n",
    "    .show(5, False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6893206",
   "metadata": {},
   "source": [
    "## 칼럼 속성 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b3d55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:57.074246Z",
     "start_time": "2023-04-05T00:25:55.764Z"
    }
   },
   "outputs": [],
   "source": [
    "fire_ts_df= (new_fire_df\n",
    "             .withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\"))\n",
    "             .drop(\"CallDate\")\n",
    "             .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\"))\n",
    "             .drop(\"WatchDate\")\n",
    "             .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "             .drop(\"AvailableDtTm\") \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060227ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:57.075207Z",
     "start_time": "2023-04-05T00:25:55.765Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fire_ts_df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e8533",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:57.076206Z",
     "start_time": "2023-04-05T00:25:55.766Z"
    }
   },
   "outputs": [],
   "source": [
    "(fire_ts_df\n",
    "    .select(\"IncidentDate\", \"OnWatchDate\",\"AvailableDtTS\")\n",
    "    .show(5, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281aa480",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:57.077206Z",
     "start_time": "2023-04-05T00:25:55.767Z"
    }
   },
   "outputs": [],
   "source": [
    "(fire_ts_df\n",
    "    .select(year(\"IncidentDate\"))\n",
    "    .distinct()\n",
    "    .orderBy(year(\"IncidentDate\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc68d05",
   "metadata": {},
   "source": [
    "## 집계 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb38a51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:57.078201Z",
     "start_time": "2023-04-05T00:25:55.768Z"
    }
   },
   "outputs": [],
   "source": [
    "(fire_ts_df\n",
    "    .select(\"CallType\")\n",
    "    .where(col('CallType').isNotNull())\n",
    "    .groupby(\"CallType\")\n",
    "    .count()\n",
    "    .orderBy(\"count\", ascending = False)\n",
    "    .show(n=10, truncate = False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecace44e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:57.079196Z",
     "start_time": "2023-04-05T00:25:55.769Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "(fire_ts_df\n",
    "    .select(F.sum(\"NumAlarms\"), F.avg(\"ResponseDelayedinMins\"),\n",
    "           F.min(\"ResponseDelayedinMins\"), F.max(\"ResponseDelayedinMins\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c35ce17",
   "metadata": {},
   "source": [
    "# 데이터세트 API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e922b74f",
   "metadata": {},
   "source": [
    "## 정적 타입 객체, 동적 타입 객체, 포괄적인 Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed331a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:57.080193Z",
     "start_time": "2023-04-05T00:25:55.770Z"
    }
   },
   "outputs": [],
   "source": [
    "row = Row(350, True, \"Learning Spark 2E\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed05ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T00:26:57.081190Z",
     "start_time": "2023-04-05T00:25:55.770Z"
    }
   },
   "outputs": [],
   "source": [
    "row[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8679b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "337.812px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
